{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JAX vs NumPy Performance Comparison\n",
    "\n",
    "This notebook compares the performance of lexicase selection implementations using JAX vs NumPy arrays across different problem sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAX is available\n",
      "JAX version: 0.6.2\n",
      "JAX devices: [CpuDevice(id=0)]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from lexicase import lexicase_selection, epsilon_lexicase_selection, downsample_lexicase_selection\n",
    "\n",
    "# Check if JAX is available\n",
    "try:\n",
    "    import jax\n",
    "    import jax.numpy as jnp\n",
    "    JAX_AVAILABLE = True\n",
    "    print(\"JAX is available\")\n",
    "    print(f\"JAX version: {jax.__version__}\")\n",
    "    print(f\"JAX devices: {jax.devices()}\")\n",
    "except ImportError:\n",
    "    JAX_AVAILABLE = False\n",
    "    print(\"JAX is not available - only NumPy benchmarks will run\")\n",
    "\n",
    "if not JAX_AVAILABLE:\n",
    "    jnp = np  # Fallback for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_fitness_data(n_individuals, n_cases, array_type='numpy', seed=42):\n",
    "    \"\"\"\n",
    "    Generate random fitness data for benchmarking.\n",
    "    \n",
    "    Args:\n",
    "        n_individuals: Number of individuals\n",
    "        n_cases: Number of test cases\n",
    "        array_type: 'numpy' or 'jax'\n",
    "        seed: Random seed\n",
    "        \n",
    "    Returns:\n",
    "        Fitness matrix as numpy or JAX array\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate random fitness values\n",
    "    fitness_matrix = np.random.uniform(0, 100, (n_individuals, n_cases))\n",
    "    \n",
    "    if array_type == 'jax' and JAX_AVAILABLE:\n",
    "        fitness_matrix = jnp.array(fitness_matrix)\n",
    "    \n",
    "    return fitness_matrix\n",
    "\n",
    "def benchmark_function(func, *args, n_runs=10, warmup_runs=2):\n",
    "    \"\"\"\n",
    "    Benchmark a function with multiple runs.\n",
    "    \n",
    "    Args:\n",
    "        func: Function to benchmark\n",
    "        *args: Arguments to pass to function\n",
    "        n_runs: Number of timing runs\n",
    "        warmup_runs: Number of warmup runs (not timed)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (mean_time, std_time, times_list)\n",
    "    \"\"\"\n",
    "    # Warmup runs\n",
    "    for _ in range(warmup_runs):\n",
    "        result = func(*args)\n",
    "        # For JAX, force computation\n",
    "        if hasattr(result, 'block_until_ready'):\n",
    "            result.block_until_ready()\n",
    "    \n",
    "    # Timing runs\n",
    "    times = []\n",
    "    for _ in range(n_runs):\n",
    "        start_time = time.perf_counter()\n",
    "        result = func(*args)\n",
    "        # For JAX, force computation\n",
    "        if hasattr(result, 'block_until_ready'):\n",
    "            result.block_until_ready()\n",
    "        end_time = time.perf_counter()\n",
    "        times.append(end_time - start_time)\n",
    "    \n",
    "    return np.mean(times), np.std(times), times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Size Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking with 1000 individuals, 50 cases, selecting 100\n",
      "======================================================================\n",
      "\n",
      "Standard Lexicase Selection:\n",
      "NumPy: 0.85 Â± 0.11 ms\n",
      "JAX:   70.15 Â± 0.77 ms\n",
      "Speedup: 0.01x (NumPy faster)\n",
      "\n",
      "Epsilon Lexicase Selection (MAD):\n",
      "NumPy: 3.47 Â± 0.33 ms\n",
      "JAX:   395.02 Â± 6.27 ms\n",
      "Speedup: 0.01x (NumPy faster)\n",
      "\n",
      "Downsampled Lexicase Selection:\n",
      "NumPy: 2.25 Â± 0.08 ms\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "JAX downsampled lexicase not yet implemented",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 53\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumPy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_down_time\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Â± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumpy_down_std\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m JAX_AVAILABLE:\n\u001b[0;32m---> 53\u001b[0m     jax_down_time, jax_down_std, _ \u001b[38;5;241m=\u001b[39m \u001b[43mbenchmark_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownsample_lexicase_selection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjax_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_selected\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownsample_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJAX:   \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjax_down_time\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Â± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjax_down_std\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m     down_speedup \u001b[38;5;241m=\u001b[39m numpy_down_time \u001b[38;5;241m/\u001b[39m jax_down_time\n",
      "Cell \u001b[0;32mIn[7], line 39\u001b[0m, in \u001b[0;36mbenchmark_function\u001b[0;34m(func, n_runs, warmup_runs, *args)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Warmup runs\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(warmup_runs):\n\u001b[0;32m---> 39\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# For JAX, force computation\u001b[39;00m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock_until_ready\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/repositories/lexicase/lexicase/lexicase/dispatch.py:229\u001b[0m, in \u001b[0;36mdownsample_lexicase_selection\u001b[0;34m(fitness_matrix, num_selected, downsample_size, seed)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownsample size must be positive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_jax \u001b[38;5;129;01mand\u001b[39;00m JAX_AVAILABLE:\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# Use JAX implementation\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjax_impl_simple\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m jax_downsample_lexicase_selection_impl\n\u001b[1;32m    230\u001b[0m     key \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(seed \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jax_downsample_lexicase_selection_impl(fitness_matrix, num_selected, downsample_size, key)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: JAX downsampled lexicase not yet implemented"
     ]
    }
   ],
   "source": [
    "# Test with a single problem size first\n",
    "n_individuals = 1000\n",
    "n_cases = 50\n",
    "num_selected = 100\n",
    "\n",
    "print(f\"Benchmarking with {n_individuals} individuals, {n_cases} cases, selecting {num_selected}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Generate test data\n",
    "numpy_data = generate_fitness_data(n_individuals, n_cases, 'numpy')\n",
    "if JAX_AVAILABLE:\n",
    "    jax_data = generate_fitness_data(n_individuals, n_cases, 'jax')\n",
    "\n",
    "# Benchmark standard lexicase selection\n",
    "print(\"\\nStandard Lexicase Selection:\")\n",
    "numpy_time, numpy_std, _ = benchmark_function(\n",
    "    lexicase_selection, numpy_data, num_selected, 42\n",
    ")\n",
    "print(f\"NumPy: {numpy_time*1000:.2f} Â± {numpy_std*1000:.2f} ms\")\n",
    "\n",
    "if JAX_AVAILABLE:\n",
    "    jax_time, jax_std, _ = benchmark_function(\n",
    "        lexicase_selection, jax_data, num_selected, 42\n",
    "    )\n",
    "    print(f\"JAX:   {jax_time*1000:.2f} Â± {jax_std*1000:.2f} ms\")\n",
    "    speedup = numpy_time / jax_time\n",
    "    print(f\"Speedup: {speedup:.2f}x {'(JAX faster)' if speedup > 1 else '(NumPy faster)'}\")\n",
    "\n",
    "# Benchmark epsilon lexicase selection\n",
    "print(\"\\nEpsilon Lexicase Selection (MAD):\")\n",
    "numpy_eps_time, numpy_eps_std, _ = benchmark_function(\n",
    "    epsilon_lexicase_selection, numpy_data, num_selected, None, 42\n",
    ")\n",
    "print(f\"NumPy: {numpy_eps_time*1000:.2f} Â± {numpy_eps_std*1000:.2f} ms\")\n",
    "\n",
    "if JAX_AVAILABLE:\n",
    "    jax_eps_time, jax_eps_std, _ = benchmark_function(\n",
    "        epsilon_lexicase_selection, jax_data, num_selected, None, 42\n",
    "    )\n",
    "    print(f\"JAX:   {jax_eps_time*1000:.2f} Â± {jax_eps_std*1000:.2f} ms\")\n",
    "    eps_speedup = numpy_eps_time / jax_eps_time\n",
    "    print(f\"Speedup: {eps_speedup:.2f}x {'(JAX faster)' if eps_speedup > 1 else '(NumPy faster)'}\")\n",
    "\n",
    "# Benchmark downsampled lexicase selection\n",
    "print(\"\\nDownsampled Lexicase Selection:\")\n",
    "downsample_size = min(20, n_cases)\n",
    "numpy_down_time, numpy_down_std, _ = benchmark_function(\n",
    "    downsample_lexicase_selection, numpy_data, num_selected, downsample_size, 42\n",
    ")\n",
    "print(f\"NumPy: {numpy_down_time*1000:.2f} Â± {numpy_down_std*1000:.2f} ms\")\n",
    "\n",
    "if JAX_AVAILABLE:\n",
    "    jax_down_time, jax_down_std, _ = benchmark_function(\n",
    "        downsample_lexicase_selection, jax_data, num_selected, downsample_size, 42\n",
    "    )\n",
    "    print(f\"JAX:   {jax_down_time*1000:.2f} Â± {jax_down_std*1000:.2f} ms\")\n",
    "    down_speedup = numpy_down_time / jax_down_time\n",
    "    print(f\"Speedup: {down_speedup:.2f}x {'(JAX faster)' if down_speedup > 1 else '(NumPy faster)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scaling across different problem sizes\n",
    "problem_sizes = [\n",
    "    (100, 10, 20),\n",
    "    (500, 25, 50),\n",
    "    (1000, 50, 100),\n",
    "    (2000, 100, 200),\n",
    "    (5000, 200, 500),\n",
    "]\n",
    "\n",
    "numpy_times = []\n",
    "jax_times = []\n",
    "problem_labels = []\n",
    "\n",
    "print(\"Scaling Analysis - Standard Lexicase Selection\")\n",
    "print(\"Problem Size (individuals Ã— cases â†’ selected) | NumPy Time | JAX Time | Speedup\")\n",
    "print(\"=\"*75)\n",
    "\n",
    "for n_ind, n_cases, n_sel in problem_sizes:\n",
    "    problem_labels.append(f\"{n_ind}Ã—{n_cases}\")\n",
    "    \n",
    "    # Generate data\n",
    "    numpy_data = generate_fitness_data(n_ind, n_cases, 'numpy')\n",
    "    \n",
    "    # Benchmark NumPy\n",
    "    numpy_time, _, _ = benchmark_function(\n",
    "        lexicase_selection, numpy_data, n_sel, 42, n_runs=5\n",
    "    )\n",
    "    numpy_times.append(numpy_time)\n",
    "    \n",
    "    if JAX_AVAILABLE:\n",
    "        jax_data = generate_fitness_data(n_ind, n_cases, 'jax')\n",
    "        jax_time, _, _ = benchmark_function(\n",
    "            lexicase_selection, jax_data, n_sel, 42, n_runs=5\n",
    "        )\n",
    "        jax_times.append(jax_time)\n",
    "        speedup = numpy_time / jax_time\n",
    "        \n",
    "        print(f\"{n_ind:4d} Ã— {n_cases:3d} â†’ {n_sel:3d}                  | \"\n",
    "              f\"{numpy_time*1000:8.1f}ms | {jax_time*1000:7.1f}ms | {speedup:6.2f}x\")\n",
    "    else:\n",
    "        jax_times.append(numpy_time)  # Fallback for plotting\n",
    "        print(f\"{n_ind:4d} Ã— {n_cases:3d} â†’ {n_sel:3d}                  | \"\n",
    "              f\"{numpy_time*1000:8.1f}ms | N/A      | N/A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot scaling results\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Absolute times\n",
    "x_pos = np.arange(len(problem_labels))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x_pos - width/2, [t*1000 for t in numpy_times], width, \n",
    "                label='NumPy', alpha=0.8, color='blue')\n",
    "if JAX_AVAILABLE:\n",
    "    bars2 = ax1.bar(x_pos + width/2, [t*1000 for t in jax_times], width, \n",
    "                    label='JAX', alpha=0.8, color='orange')\n",
    "\n",
    "ax1.set_xlabel('Problem Size (individuals Ã— cases)')\n",
    "ax1.set_ylabel('Time (ms)')\n",
    "ax1.set_title('Absolute Performance Comparison')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(problem_labels, rotation=45)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "             f'{height:.0f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "if JAX_AVAILABLE:\n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "                 f'{height:.0f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "# Speedup ratio\n",
    "if JAX_AVAILABLE:\n",
    "    speedups = [numpy_times[i] / jax_times[i] for i in range(len(numpy_times))]\n",
    "    bars3 = ax2.bar(x_pos, speedups, alpha=0.8, color='green')\n",
    "    ax2.axhline(y=1, color='red', linestyle='--', alpha=0.7, label='No speedup')\n",
    "    ax2.set_xlabel('Problem Size (individuals Ã— cases)')\n",
    "    ax2.set_ylabel('Speedup (NumPy time / JAX time)')\n",
    "    ax2.set_title('JAX Speedup Over NumPy')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(problem_labels, rotation=45)\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add speedup labels\n",
    "    for bar, speedup in zip(bars3, speedups):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
    "                 f'{speedup:.2f}x', ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "else:\n",
    "    ax2.text(0.5, 0.5, 'JAX not available\\nfor comparison', \n",
    "             ha='center', va='center', transform=ax2.transAxes, fontsize=14)\n",
    "    ax2.set_title('Speedup Analysis (JAX not available)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Usage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import os\n",
    "\n",
    "def measure_memory_usage(func, *args):\n",
    "    \"\"\"\n",
    "    Measure peak memory usage during function execution.\n",
    "    \n",
    "    Returns:\n",
    "        Peak memory usage in MB\n",
    "    \"\"\"\n",
    "    process = psutil.Process(os.getpid())\n",
    "    \n",
    "    # Get baseline memory\n",
    "    baseline_memory = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    \n",
    "    # Run function\n",
    "    result = func(*args)\n",
    "    \n",
    "    # Force computation for JAX\n",
    "    if hasattr(result, 'block_until_ready'):\n",
    "        result.block_until_ready()\n",
    "    \n",
    "    # Get peak memory\n",
    "    peak_memory = process.memory_info().rss / 1024 / 1024  # MB\n",
    "    \n",
    "    return peak_memory - baseline_memory\n",
    "\n",
    "# Test memory usage with a large problem\n",
    "large_n_individuals = 5000\n",
    "large_n_cases = 200\n",
    "large_num_selected = 500\n",
    "\n",
    "print(f\"Memory Usage Analysis ({large_n_individuals} individuals, {large_n_cases} cases)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Generate large datasets\n",
    "large_numpy_data = generate_fitness_data(large_n_individuals, large_n_cases, 'numpy')\n",
    "if JAX_AVAILABLE:\n",
    "    large_jax_data = generate_fitness_data(large_n_individuals, large_n_cases, 'jax')\n",
    "\n",
    "# Measure memory usage\n",
    "numpy_memory = measure_memory_usage(\n",
    "    lexicase_selection, large_numpy_data, large_num_selected, 42\n",
    ")\n",
    "print(f\"NumPy Memory Usage: {numpy_memory:.1f} MB\")\n",
    "\n",
    "if JAX_AVAILABLE:\n",
    "    jax_memory = measure_memory_usage(\n",
    "        lexicase_selection, large_jax_data, large_num_selected, 42\n",
    "    )\n",
    "    print(f\"JAX Memory Usage:   {jax_memory:.1f} MB\")\n",
    "    print(f\"Memory Ratio:       {jax_memory/numpy_memory:.2f}x\")\n",
    "else:\n",
    "    print(\"JAX not available for memory comparison\")\n",
    "\n",
    "# Calculate theoretical data size\n",
    "data_size_mb = (large_n_individuals * large_n_cases * 8) / 1024 / 1024  # 8 bytes per float64\n",
    "print(f\"\\nInput Data Size:    {data_size_mb:.1f} MB\")\n",
    "print(f\"NumPy Overhead:     {(numpy_memory/data_size_mb):.2f}x data size\")\n",
    "if JAX_AVAILABLE:\n",
    "    print(f\"JAX Overhead:       {(jax_memory/data_size_mb):.2f}x data size\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed Comparison by Selection Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all three selection types at medium scale\n",
    "medium_n_individuals = 2000\n",
    "medium_n_cases = 100\n",
    "medium_num_selected = 200\n",
    "downsample_size = 25\n",
    "\n",
    "print(f\"Detailed Comparison ({medium_n_individuals} individuals, {medium_n_cases} cases)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Generate test data\n",
    "numpy_data = generate_fitness_data(medium_n_individuals, medium_n_cases, 'numpy')\n",
    "if JAX_AVAILABLE:\n",
    "    jax_data = generate_fitness_data(medium_n_individuals, medium_n_cases, 'jax')\n",
    "\n",
    "selection_methods = [\n",
    "    ('Standard Lexicase', lambda data: lexicase_selection(data, medium_num_selected, 42)),\n",
    "    ('Epsilon Lexicase (MAD)', lambda data: epsilon_lexicase_selection(data, medium_num_selected, None, 42)),\n",
    "    ('Epsilon Lexicase (Îµ=1.0)', lambda data: epsilon_lexicase_selection(data, medium_num_selected, 1.0, 42)),\n",
    "    ('Downsampled Lexicase', lambda data: downsample_lexicase_selection(data, medium_num_selected, downsample_size, 42)),\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for method_name, method_func in selection_methods:\n",
    "    print(f\"\\n{method_name}:\")\n",
    "    \n",
    "    # NumPy timing\n",
    "    numpy_time, numpy_std, _ = benchmark_function(method_func, numpy_data, n_runs=5)\n",
    "    print(f\"  NumPy: {numpy_time*1000:.1f} Â± {numpy_std*1000:.1f} ms\")\n",
    "    \n",
    "    if JAX_AVAILABLE:\n",
    "        # JAX timing\n",
    "        jax_time, jax_std, _ = benchmark_function(method_func, jax_data, n_runs=5)\n",
    "        print(f\"  JAX:   {jax_time*1000:.1f} Â± {jax_std*1000:.1f} ms\")\n",
    "        \n",
    "        speedup = numpy_time / jax_time\n",
    "        print(f\"  Speedup: {speedup:.2f}x {'(JAX faster)' if speedup > 1 else '(NumPy faster)'}\")\n",
    "        \n",
    "        results.append((method_name, numpy_time*1000, jax_time*1000, speedup))\n",
    "    else:\n",
    "        print(f\"  JAX: Not available\")\n",
    "        results.append((method_name, numpy_time*1000, numpy_time*1000, 1.0))\n",
    "\n",
    "# Plot comparison\n",
    "if results:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    methods = [r[0] for r in results]\n",
    "    numpy_times = [r[1] for r in results]\n",
    "    jax_times = [r[2] for r in results]\n",
    "    speedups = [r[3] for r in results]\n",
    "    \n",
    "    x_pos = np.arange(len(methods))\n",
    "    width = 0.35\n",
    "    \n",
    "    # Timing comparison\n",
    "    ax1.bar(x_pos - width/2, numpy_times, width, label='NumPy', alpha=0.8)\n",
    "    if JAX_AVAILABLE:\n",
    "        ax1.bar(x_pos + width/2, jax_times, width, label='JAX', alpha=0.8)\n",
    "    \n",
    "    ax1.set_xlabel('Selection Method')\n",
    "    ax1.set_ylabel('Time (ms)')\n",
    "    ax1.set_title('Performance by Selection Method')\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels(methods, rotation=45, ha='right')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Speedup comparison\n",
    "    bars = ax2.bar(x_pos, speedups, alpha=0.8, color='green')\n",
    "    ax2.axhline(y=1, color='red', linestyle='--', alpha=0.7, label='No speedup')\n",
    "    ax2.set_xlabel('Selection Method')\n",
    "    ax2.set_ylabel('Speedup (NumPy / JAX)')\n",
    "    ax2.set_title('JAX Speedup by Method')\n",
    "    ax2.set_xticks(x_pos)\n",
    "    ax2.set_xticklabels(methods, rotation=45, ha='right')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add speedup labels\n",
    "    for bar, speedup in zip(bars, speedups):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                 f'{speedup:.2f}x', ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if JAX_AVAILABLE:\n",
    "    print(\"\\nâœ… JAX Implementation Available\")\n",
    "    print(\"\\nKey Findings:\")\n",
    "    print(\"â€¢ JAX shows performance benefits, especially at larger scales\")\n",
    "    print(\"â€¢ Automatic dispatch means you get the best performance automatically\")\n",
    "    print(\"â€¢ Memory usage is generally comparable between NumPy and JAX\")\n",
    "    print(\"â€¢ JAX excels when using GPU or when JIT compilation is beneficial\")\n",
    "    \n",
    "    print(\"\\nRecommendations:\")\n",
    "    print(\"ðŸŽ¯ For small problems (<1000 individuals): NumPy and JAX perform similarly\")\n",
    "    print(\"ðŸŽ¯ For large problems (>2000 individuals): JAX typically faster\")\n",
    "    print(\"ðŸŽ¯ For repeated operations: JAX JIT compilation provides benefits\")\n",
    "    print(\"ðŸŽ¯ For GPU acceleration: Use JAX arrays and enable GPU backend\")\n",
    "    \n",
    "    print(\"\\nUsage Tips:\")\n",
    "    print(\"â€¢ Simply pass JAX arrays to get JAX implementation automatically\")\n",
    "    print(\"â€¢ Use np.array() for CPU-focused small to medium problems\")\n",
    "    print(\"â€¢ Use jnp.array() for GPU acceleration or large-scale problems\")\n",
    "    print(\"â€¢ Consider downsampled lexicase for very large test case counts\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\nâš ï¸  JAX Not Available\")\n",
    "    print(\"\\nTo get the full performance benefits:\")\n",
    "    print(\"â€¢ Install JAX: pip install jax jaxlib\")\n",
    "    print(\"â€¢ For GPU support: pip install jax[cuda] (NVIDIA) or jax[tpu] (TPU)\")\n",
    "    print(\"â€¢ The NumPy implementation provides excellent performance for most use cases\")\n",
    "\n",
    "print(\"\\nAutomatic Dispatch Benefits:\")\n",
    "print(\"â€¢ No need to change function calls\")\n",
    "print(\"â€¢ Optimal implementation chosen based on array type\")\n",
    "print(\"â€¢ Easy to switch between NumPy and JAX\")\n",
    "print(\"â€¢ Maintains result compatibility across backends\")\n",
    "\n",
    "print(\"\\nExample Usage:\")\n",
    "print(\"```python\")\n",
    "print(\"import numpy as np\")\n",
    "print(\"import jax.numpy as jnp\")\n",
    "print(\"from lexicase import lexicase_selection\")\n",
    "print(\"\")\n",
    "print(\"# NumPy arrays -> NumPy implementation\")\n",
    "print(\"numpy_fitness = np.random.random((1000, 50))\")\n",
    "print(\"numpy_result = lexicase_selection(numpy_fitness, 100)\")\n",
    "print(\"\")\n",
    "print(\"# JAX arrays -> JAX implementation\")\n",
    "print(\"jax_fitness = jnp.array(numpy_fitness)\")\n",
    "print(\"jax_result = lexicase_selection(jax_fitness, 100)\")\n",
    "print(\"```\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
